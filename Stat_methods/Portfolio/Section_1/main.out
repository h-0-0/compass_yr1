\BOOKMARK [1][-]{section.1}{Introduction to Decision-Making}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{LS with Feature Transform}{section.1}% 2
\BOOKMARK [1][-]{section.2}{Overfitting and the curse of dimensionality}{}% 3
\BOOKMARK [2][-]{subsection.2.1}{Overfitting}{section.2}% 4
\BOOKMARK [2][-]{subsection.2.2}{Cross-Validation}{section.2}% 5
\BOOKMARK [2][-]{subsection.2.3}{Curse of dimensionality}{section.2}% 6
\BOOKMARK [1][-]{section.3}{Regularization and a Probabilistic View of Regression}{}% 7
\BOOKMARK [2][-]{subsection.3.1}{Regularization}{section.3}% 8
\BOOKMARK [2][-]{subsection.3.2}{A Probabilistic View of Regression}{section.3}% 9
\BOOKMARK [1][-]{section.4}{Risk and Bayes Optimal Prediction}{}% 10
\BOOKMARK [2][-]{subsection.4.1}{Inference of TEXT}{section.4}% 11
\BOOKMARK [2][-]{subsection.4.2}{Risk in Regression}{section.4}% 12
\BOOKMARK [1][-]{section*.1}{Appendices}{}% 13
\BOOKMARK [1][-]{appendix.a.A}{Proofs}{}% 14
\BOOKMARK [2][-]{subsection.a.A.1}{Proof of eqn:wLS solution}{appendix.a.A}% 15
\BOOKMARK [2][-]{subsection.a.A.2}{Proof of eqn:w-LS-R solution}{appendix.a.A}% 16
\BOOKMARK [2][-]{subsection.a.A.3}{Proof of TEXT when TEXT}{appendix.a.A}% 17
\BOOKMARK [2][-]{subsection.a.A.4}{Proof of eqn:complicated-integral}{appendix.a.A}% 18
\BOOKMARK [2][-]{subsection.a.A.5}{TEXT minimized when TEXT }{appendix.a.A}% 19
\BOOKMARK [2][-]{subsection.a.A.6}{The optimal prediction using squared loss is TEXT}{appendix.a.A}% 20
\BOOKMARK [2][-]{subsection.a.A.7}{The optimal prediction using absolute loss is the median of TEXT}{appendix.a.A}% 21
\BOOKMARK [1][-]{appendix.a.B}{Homeworks}{}% 22
\BOOKMARK [2][-]{subsection.a.B.1}{For Section 1}{appendix.a.B}% 23
\BOOKMARK [2][-]{subsection.a.B.2}{For Section 2}{appendix.a.B}% 24
\BOOKMARK [2][-]{subsection.a.B.3}{For Section 3}{appendix.a.B}% 25
