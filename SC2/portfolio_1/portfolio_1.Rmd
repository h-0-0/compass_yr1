---
title: "portfolio_1"
author: "Henry Bourne"
date: "2023-01-30"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = TRUE)
```

# Intro to C++
In this document we will go over the basics of C++, the idea of this document is for it to act as a quick reference sheet to refresh on C++ syntax should I forget. We will use bash to print out and run C++ files all of which (along with this R markdown file can be found on my github: "github.com/h-aze/compass_yr1/SC2"). Some explanation I will give before the code chunks and some I will give in the comments of the C++ files. 

## The basics
We will start by covering the basics which is all contained in the "intro.cpp" file, lets print it out and run it:
```{r, engine = 'bash'}
cat intro_to_cpp/intro.cpp
```
```{r, engine = 'bash'}
g++ intro_to_cpp/intro.cpp -o intro_to_cpp/intro
./intro_to_cpp/intro
```

## Types
Let's now discuss types in more detail:
```{r, engine = 'bash'}
cat intro_to_cpp/types.cpp
```
```{r, engine = 'bash'}
g++ intro_to_cpp/types.cpp -o intro_to_cpp/types
./intro_to_cpp/types
```

## Scope
Scope is controlled by "{}", anything defined in the brackets is only available in the brackets. It is also defined by files, anything defined in a file is only available in that file, unless we import of course (we will discuss this later). Note that if we have multiple definitions of a variable in different levels of nests we use the definition of the inner most nest we currently are in.  

## Vectors and Dictionaries
```{r, engine = 'bash'}
cat intro_to_cpp/vector_dict.cpp
```
```{r, engine = 'bash'}
g++ intro_to_cpp/vector_dict.cpp -o intro_to_cpp/vector_dict
./intro_to_cpp/vector_dict
```

## Multi-File Programmes
In C++ we use something called a header file (uses the ".h" extension). Header files are where you store all your function declarations and in the .cpp files you should store all your function definitions and main code. What this achieves is a separation between interface (the header file) and implementation (the .cpp file). To use the function declarations in your cpp file you must use "#include". If we then want to use a function that was declared in a header file but defined elsewhere all we must do is "#include" the header file, this is how we use functions from standard libraries. There are two ways of "#include"-ing: 
```{r, eval = FALSE}
#include <standard_library_name>

#include "user_defined_library"
```
Another thing to mention that we haven't yet is that you can overload functions, ie. you can create multiple instances of a function that take different types and at run time the definition of the function that has the correct types and number of arguments is used. Before moving on we will mention header guards, we must include these to prevent the situation where we copy are code in twice (if we have two includes of the same thing in our code for example), at the top of the file one should write:
```{r}
#ifndef _FILENAME_H

#define _FILENAME_H
```
and at the bottom:
```{r}
#endif
```
Finally we should have a file named "main.cpp" where we keep our main function. 

## Objects, Classes, Concepts, Default Arguments and Operators
Finally we will talk briefly about objects, classes, concepts, default arguments and operators. We can declare a class in C (in the header file!) using the following syntax:
```{r}
#'class ClassName
#'{
#'public:
#'    ClassName(type arg); //This is the constructor (or initialization) method 
#'  
#'    type class_method(type arg);
#'  
#'private:
#'    type an_attribute;
#'};
```
We can then define a method we have declared in a .cpp file using the following syntax:
```{r}
#'ClassName::name_of_class_method(type arg)
#'{
#'  do something 
#'}
```
If we want to change the value of an attribute we can do it as follows:
```{r}
#'this->attribute_name = value;
```
We can initialize a class as follows:
```{r}
#'ClassName obj(init_param);
```
And then use a method as follows:
```{r}
#'obj.method_name(params);
```

Now we will talk about operators. For classes in C++ we can define operators, operators are functions that are added to classes to specify what code should be used when we operate on them with other classes. Examples of key operators are:
```{r}
#;operator+ : addition
#;operator- : subtraction
#;operator* : multiplication
#;operator/ : division
#;bool operator== : comparison equals to,
#;bool operator!= : not equal to
#;bool operator< : less than
#;bool operator<= : less than or equal to
#;bool operator> : greater than
#;bool operator>= : greater than or equal to
```
We can declare an operator for a class like so:
```{r}
#'ClassName operator+(ClassName arg_name);
```
And then define it like so:
```{r}
#'ClassName ClassName::operator+(ClassName arg_name)
#'{
#'    do and return something
#'}
```
This concludes the intro to C++!

# Let's Get Some C++ Practice!
To get coding some more C++ we will now move onto a project I have done in C++. The project was to create, train and test a neural network all written in C++. I wrote the neural network completely from scratch using only the standard C++ libraries in order to get some good C++ practice and to get more familiar with some of the details of how a neural network works.

## Creating a Neural Network
The neural network class is defined in the "Neural_Net.h" file, we will now print out the header file so we can get an idea of what the class looks like:
```{r, engine = 'bash'}
cat neural_network/Neural_Net.h
```
We can see that the class has a constructor, a destructor, a method to forward propogate through the network and a method to back propogate through the network for a mini-batch of datapoints (the network is trained using mini-batch gradient descent). There is also the layer class which contains methods for forward and back propogation through the individual layer which the neural network class makes use of. For now the only activation function we have defined is the ReLU function and the only kind of layers we have defined are fully connected layers. We also currently can only use the MSE as our loss and so in future it would be good to add cross entropy loss for when carrying out classification tasks for example. However, it should be straightforward to add more activation functions, loss functions and layer types such as convolutional layers.

Let's now look at the "Optimizer.h" file:
```{r, engine = 'bash'}
cat neural_network/Optimizer.h
```
We can see that the optimizer class has a constructor, a destructor, methods to retrieve training, testing and validation data, a method to train the network and a method to test the network among other things. The Optimizer class makes use of templates so that it can work with any kind of data. We can use the train() method to train a network on some data for a given number of epochs, for each epoch it will train the network on all the data and then test the network on the test data printing the loss. Some work remains to be done to log the loss and accuracies for each epoch and plot them, fully implement the use of validation data (at the moment it just uses the test data) and implement early stopping, learning rate schedules, etc. 

The way we could create a network is instantiate a vector of layers and initialize the neural network class with it. We could then instantiate an optimizer with some data and our neural network and train the network. My hope was to create a wrapper for the classes with Rcpp so that we could use the neural network in R and try out the network on some data! but I have not quite had the time to do so. I am fairly confident, however, that the code should work (or at least be very close to working) as I have written extensive unit tests for the code using google test, which my code passes. In the appendix you can see all the tests for yourself, but for now lets just run the tests:
```{r, engine = 'bash'}
cd neural_network
make
./runTests
```
Further work with this code that I would also like to finish at some point is paralleling the training of the network to speed it up along with other things mentioned earlier. After this project my C++ knowledge certainly feels much sounder although its a shame I couldn't quite round the whole thing off by interfacing with Rcpp and training it on some data! But I perhaps bit off more than I can chew given the time frame! The next section I have printed off some of the implementation code, but again, please check my Github as it may be easier to read there.  

## Appendix: The implementations of the header files and the unit tests
I will now print out the implementations of the header files if you are interested in taking a look at how all the methods were implemented:
```{r, engine = 'bash'}
cat neural_network/Neural_Net.cpp
```

```{r, engine = 'bash'}
cat neural_network/Optimizer.tpp
```

Finally I will print out the unit tests:
```{r, engine = 'bash'}
cat neural_network/Unit_Tests.cpp
```